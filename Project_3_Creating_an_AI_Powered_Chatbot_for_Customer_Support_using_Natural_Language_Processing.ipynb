{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF4rNjp7b9YCShBysiIHPe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhu2s6361/Creating-an-AI-Powered-Chatbot-for-Customer-Support-using-Natural-Language-Processing/blob/main/Project_3_Creating_an_AI_Powered_Chatbot_for_Customer_Support_using_Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9I8EDxc3y6Vp"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q scikit-learn nltk joblib gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create intents.json\n",
        "import json\n",
        "\n",
        "intents = {\n",
        "    \"intents\": [\n",
        "        {\n",
        "            \"tag\": \"greeting\",\n",
        "            \"patterns\": [\"hi\", \"hello\", \"hey\", \"good morning\", \"good evening\", \"hey there\"],\n",
        "            \"responses\": [\"Hello! How can I help you today?\", \"Hi there — what can I do for you?\"]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"goodbye\",\n",
        "            \"patterns\": [\"bye\", \"goodbye\", \"see you\", \"talk to you later\"],\n",
        "            \"responses\": [\"Goodbye! Have a nice day.\", \"See you later — reach out if you need anything else.\"]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"thanks\",\n",
        "            \"patterns\": [\"thanks\", \"thank you\", \"thx\", \"thank you very much\"],\n",
        "            \"responses\": [\"You're welcome!\", \"Happy to help!\"]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"order_status\",\n",
        "            \"patterns\": [\n",
        "                \"where is my order\", \"track my order\", \"order status\",\n",
        "                \"track order\", \"order tracking\", \"what's the status of my order\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"Can you please provide your order ID? I can check the status for you.\",\n",
        "                \"Sure — share your order ID and I’ll look it up.\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"product_info\",\n",
        "            \"patterns\": [\n",
        "                \"tell me about product\", \"product info\", \"what is this product\",\n",
        "                \"details about product\", \"product specifications\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"Which product would you like information about? Please share the product name or SKU.\",\n",
        "                \"Tell me the product name and I'll provide details.\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"refund_policy\",\n",
        "            \"patterns\": [\n",
        "                \"refund\", \"how to return\", \"return policy\",\n",
        "                \"I want a refund\", \"how do I return a product\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"Our refund policy allows returns within 30 days with a receipt. Would you like to start a return?\",\n",
        "                \"You can return items within 30 days. Do you want me to create a return request?\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"complaint\",\n",
        "            \"patterns\": [\n",
        "                \"I have a complaint\", \"this is broken\", \"item arrived damaged\",\n",
        "                \"not working\", \"I'm unhappy with my purchase\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"I'm sorry to hear that. Please tell me the order ID and a brief description of the problem.\",\n",
        "                \"Apologies for that — can you give me the order ID so we can resolve it?\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"unknown\",\n",
        "            \"patterns\": [],\n",
        "            \"responses\": [\n",
        "                \"Sorry, I didn't understand that. Could you rephrase or ask something else?\",\n",
        "                \"I’m not sure I understood. Could you give more details or try different words?\"\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(\"intents.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(intents, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(\"Saved intents.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy-fgEyDy92m",
        "outputId": "97cc69c8-0372-44df-e302-27dce9b6fb5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved intents.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Required downloads (including punkt_tab to avoid the LookupError)\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")   # Fix for newer NLTK layouts\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il-daCVSzCjK",
        "outputId": "9ab1fad3-c26d-4e68-e267-eea1af7158bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import joblib\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "STEMMER = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text: str) -> str:\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [t for t in tokens if t.isalpha() and t not in STOPWORDS]\n",
        "    stems = [STEMMER.stem(t) for t in tokens]\n",
        "    return \" \".join(stems)\n",
        "\n",
        "def load_intents(path=\"intents.json\"):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    X, y, tag_to_responses = [], [], {}\n",
        "    for intent in data[\"intents\"]:\n",
        "        tag = intent[\"tag\"]\n",
        "        tag_to_responses[tag] = intent.get(\"responses\", [])\n",
        "        for p in intent.get(\"patterns\", []):\n",
        "            X.append(preprocess_text(p))\n",
        "            y.append(tag)\n",
        "    return X, y, tag_to_responses\n",
        "\n",
        "print(\"Loading intents...\")\n",
        "X, y, tag_to_responses = load_intents()\n",
        "print(f\"{len(X)} patterns, {len(set(y))} tags\")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=2000)),\n",
        "    (\"clf\", LogisticRegression(max_iter=300))\n",
        "])\n",
        "\n",
        "print(\"Training...\")\n",
        "pipeline.fit(X, y)\n",
        "bundle = {\"pipeline\": pipeline, \"tag_to_responses\": tag_to_responses}\n",
        "joblib.dump(bundle, \"model.pkl\")\n",
        "print(\"Model trained and saved to model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sDBGsR2zEco",
        "outputId": "d7c4b91a-5e9a-41cf-8f98-6f1f9ef95177"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading intents...\n",
            "35 patterns, 7 tags\n",
            "Training...\n",
            "Model trained and saved to model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple test loop (works inside a Colab cell)\n",
        "import joblib, random, sys\n",
        "bundle = joblib.load(\"model.pkl\")\n",
        "pipeline = bundle[\"pipeline\"]\n",
        "tag_to_responses = bundle[\"tag_to_responses\"]\n",
        "\n",
        "def predict(text, threshold=0.45):\n",
        "    proc = preprocess_text(text)\n",
        "    probs = pipeline.predict_proba([proc])[0]\n",
        "    classes = pipeline.classes_\n",
        "    best_idx = probs.argmax()\n",
        "    best_prob = probs[best_idx]\n",
        "    best_tag = classes[best_idx]\n",
        "    if best_prob < threshold:\n",
        "        return \"unknown\", best_prob\n",
        "    return best_tag, best_prob\n",
        "\n",
        "def bot_reply(msg):\n",
        "    tag, prob = predict(msg)\n",
        "    resp = random.choice(tag_to_responses.get(tag, tag_to_responses[\"unknown\"]))\n",
        "    return f\"Bot: {resp} (intent={tag}, conf={prob:.2f})\"\n",
        "\n",
        "# Example manual test:\n",
        "print(bot_reply(\"hi\"))\n",
        "print(bot_reply(\"where is my order\"))\n",
        "print(bot_reply(\"I want a refund\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYIyU_t5zIzT",
        "outputId": "12d63295-50f3-496f-d547-1030a1e283ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: Sorry, I didn't understand that. Could you rephrase or ask something else? (intent=unknown, conf=0.33)\n",
            "Bot: Sure — share your order ID and I’ll look it up. (intent=order_status, conf=0.53)\n",
            "Bot: Sorry, I didn't understand that. Could you rephrase or ask something else? (intent=unknown, conf=0.35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to open a small web UI in Colab (click the external link that appears)\n",
        "import gradio as gr\n",
        "\n",
        "def respond_gradio(message):\n",
        "    return bot_reply(message)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=respond_gradio,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Type your message here...\"),\n",
        "    outputs=gr.Textbox(label=\"Chatbot response\"),\n",
        "    title=\"NLP Customer Support Chatbot\",\n",
        "    description=\"Simple TF-IDF + LogisticRegression intent-based chatbot demo.\"\n",
        ")\n",
        "\n",
        "# In Colab, use share=True to get a public link; remove share for local usage only\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "10ZXMN79zKyQ",
        "outputId": "72e44580-ad2e-4267-983a-6db1a8bccdf7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d41bdec5923454c542.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d41bdec5923454c542.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GRbnXCa1zOiW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}